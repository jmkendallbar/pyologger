{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `pyologger` data processing pipeline with `DiveDB`\n",
    "Uses classes `Metadata` and `DataReader` to facilitate data intake, processing, and alignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read deployment metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and set working directory (adjust to fit your preferences)\n",
    "import os\n",
    "import pickle\n",
    "from pyologger.load_data.datareader import DataReader\n",
    "from pyologger.load_data.metadata import Metadata\n",
    "from pyologger.plot_data.plotter import *\n",
    "from pyologger.calibrate_data.calibrate_acc_mag import *\n",
    "\n",
    "\n",
    "# Change the current working directory to the root directory\n",
    "# os.chdir(\"/Users/fbar/Documents/GitHub/pyologger\")\n",
    "os.chdir(\"/Users/jessiekb/Documents/GitHub/pyologger\")\n",
    "\n",
    "root_dir = os.getcwd()\n",
    "data_dir = os.path.join(root_dir, \"data\")\n",
    "\n",
    "# Verify the current working directory\n",
    "print(f\"Current working directory: {root_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "#import netcdf4\n",
    "\n",
    "# Load the NetCDF file\n",
    "file_path = f\"{data_dir}/2004001_TrackTDR_RawCurated.nc\"\n",
    "dataset = xr.open_dataset(file_path)\n",
    "\n",
    "# Print the dataset information\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the info class\n",
    "metadata = Metadata()\n",
    "metadata.fetch_databases(verbose=False)\n",
    "\n",
    "# Save databases\n",
    "dep_db = metadata.get_metadata(\"dep_DB\")\n",
    "logger_db = metadata.get_metadata(\"logger_DB\")\n",
    "rec_db = metadata.get_metadata(\"rec_DB\")\n",
    "animal_db = metadata.get_metadata(\"animal_DB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the deployment dataframe.\n",
    "dep_db_sorted = dep_db.sort_values('Rec Date')\n",
    "dep_db_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files in deployment folder\n",
    "\n",
    "Steps for Processing Deployment Data:\n",
    "\n",
    "1. **Select Deployment Folder**:\n",
    "   - **Description:** Asks the user for input to select a deployment folder to kick off the data reading process. In your folder name, you can have any suffix after Deployment ID. It will check and stop if there are two that fit.\n",
    "   - **Function Used:** `check_deployment_folder()`\n",
    "\n",
    "2. **Initialize Deployment Folder**:\n",
    "   - **Description:** Starts the main `read_files` process with the selected deployment folder.\n",
    "   - **Function Used:** `read_files()`\n",
    "\n",
    "3. **Fetch Metadata**:\n",
    "   - **Description:** Retrieve necessary data from the metadata database, including logger information.\n",
    "   - **Function Used:** `metadata.fetch_databases()`\n",
    "\n",
    "4. **Organize Files by Logger ID**:\n",
    "   - **Description:** Group files by logger ID for processing.\n",
    "   - **Function Used:** `read_files()` (This is the main function)\n",
    "\n",
    "5. **Check for Existing Processed Files**:\n",
    "   - **Description:** Verify if the outputs folder already contains processed files for each logger. Skip reprocessing if all necessary files are present.\n",
    "   - **Function Used:** `check_outputs_folder()`\n",
    "\n",
    "6. **Process UBE Files**:\n",
    "   - **Description:** For each UFI logger with UBE files, process and save the data.\n",
    "   - **Function Used:** `process_ube_file()`\n",
    "\n",
    "7. **Process CSV Files**:\n",
    "   - **Description:** For each logger with multiple CSV files, concatenate them, and save the combined data.\n",
    "   - **Function Used:** `concatenate_and_save_csvs()`\n",
    "\n",
    "8. **Final Outputs**:\n",
    "   - **Description:** Ensure all processed data is saved in the outputs folder with appropriate filenames.\n",
    "   - **Functions Used:** `save_data()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the metadata and dep_db loaded:\n",
    "datareader = DataReader()\n",
    "deployment_folder = datareader.check_deployment_folder(dep_db, data_dir)\n",
    "\n",
    "if deployment_folder:\n",
    "    datareader.read_files(metadata, save_csv=True, save_parq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally look at first notes that have been read in\n",
    "#datareader.selected_deployment['Time Zone']\n",
    "#datareader.info['UF-01']\n",
    "datareader.notes_df[0:5]\n",
    "#datareader.data['CC-96']\n",
    "#datareader.data['UF-01']\n",
    "#datareader.metadata['channelnames']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data_reader object from the pickle file\n",
    "pkl_path = os.path.join(deployment_folder, 'outputs', 'data.pkl')\n",
    "\n",
    "with open(pkl_path, 'rb') as file:\n",
    "    data_pkl = pickle.load(file)\n",
    "\n",
    "for logger_id, info in data_pkl.info.items():\n",
    "    sampling_frequency = info.get('datetime_metadata', {}).get('fs', None)\n",
    "    if sampling_frequency is not None:\n",
    "        # Format the sampling frequency to 5 significant digits\n",
    "        print(f\"Sampling frequency for {logger_id}: {sampling_frequency} Hz\")\n",
    "    else:\n",
    "        print(f\"No sampling frequency available for {logger_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data\n",
    "Make an interactive plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load color mappings\n",
    "color_mapping_path = os.path.join(root_dir, 'color_mappings.json')\n",
    "\n",
    "# Streamlit sidebar for time range selection\n",
    "imu_logger_to_use = 'CC-96'\n",
    "ephys_logger_to_use = 'UF-01'\n",
    "\n",
    "imu_df = data_pkl.data[imu_logger_to_use]\n",
    "ephys_df = data_pkl.data[ephys_logger_to_use]\n",
    "overlap_start_time = max(imu_df['datetime'].min(), ephys_df['datetime'].min()).to_pydatetime()\n",
    "overlap_end_time = min(imu_df['datetime'].max(), ephys_df['datetime'].max()).to_pydatetime()\n",
    "\n",
    "# Define notes to plot\n",
    "notes_to_plot = {\n",
    "    'heartbeat_manual_ok': 'ecg',\n",
    "    'exhalation_breath': 'depth'\n",
    "}\n",
    "\n",
    "# Plotting\n",
    "fig = plot_tag_data_interactive(data_pkl, imu_channels=['depth', 'accX', 'accY', 'accZ', 'gyrX', 'gyrY', 'gyrZ', 'magX', 'magY', 'magZ'], \n",
    "                                ephys_channels=['ecg'], \n",
    "                                imu_logger=imu_logger_to_use, \n",
    "                                ephys_logger=ephys_logger_to_use, \n",
    "                                time_range=(overlap_start_time, overlap_end_time), \n",
    "                                note_annotations=notes_to_plot, \n",
    "                                color_mapping_path=color_mapping_path)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting again (this takes longer without subplots but allows you to track the time across all plots in a grid)\n",
    "fig = plot_tag_data_interactive2(data_pkl, imu_channels=['depth', 'accX', 'accY', 'accZ', 'gyrX', 'gyrY', 'gyrZ', 'magX', 'magY', 'magZ'], \n",
    "                                ephys_channels=['ecg'], \n",
    "                                imu_logger=imu_logger_to_use, \n",
    "                                ephys_logger=ephys_logger_to_use, \n",
    "                                time_range=(overlap_start_time, overlap_end_time), \n",
    "                                note_annotations=notes_to_plot, \n",
    "                                color_mapping_path=color_mapping_path)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "# Function to apply a low-pass filter to extract the static component (gravity)\n",
    "def low_pass_filter(data, cutoff, fs, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    filtered_data = filtfilt(b, a, data)\n",
    "    return filtered_data\n",
    "\n",
    "# Function to calculate ODBA\n",
    "def calculate_odba(accX, accY, accZ, cutoff=0.1, fs=10):\n",
    "    # Apply low-pass filter to get the static acceleration\n",
    "    accX_static = low_pass_filter(accX, cutoff, fs)\n",
    "    accY_static = low_pass_filter(accY, cutoff, fs)\n",
    "    accZ_static = low_pass_filter(accZ, cutoff, fs)\n",
    "\n",
    "    # Subtract the static component to get the dynamic acceleration\n",
    "    accX_dynamic = accX - accX_static\n",
    "    accY_dynamic = accY - accY_static\n",
    "    accZ_dynamic = accZ - accZ_static\n",
    "\n",
    "    # Calculate ODBA\n",
    "    odba = np.abs(accX_dynamic) + np.abs(accY_dynamic) + np.abs(accZ_dynamic)\n",
    "    \n",
    "    return odba\n",
    "\n",
    "# Example usage with your data\n",
    "accX = data_pkl.data['CC-96']['accX_adjusted'].values\n",
    "accY = data_pkl.data['CC-96']['accY_adjusted'].values\n",
    "accZ = data_pkl.data['CC-96']['accZ_adjusted'].values\n",
    "\n",
    "odba = calculate_odba(accX, accY, accZ)\n",
    "\n",
    "data_pkl.data['CC-96']['odba'] = odba\n",
    "\n",
    "imu_channels_to_plot = ['depth', 'accX', 'accY', 'accZ', 'odba', 'pitch_deg', 'roll_deg', 'heading_deg']\n",
    "ephys_channels_to_plot = []\n",
    "imu_logger_to_use = 'CC-96'\n",
    "ephys_logger_to_use = 'UF-01'\n",
    "\n",
    "# Get the overlapping time range\n",
    "imu_df = data_pkl.data[imu_logger_to_use]\n",
    "ephys_df = data_pkl.data[ephys_logger_to_use]\n",
    "start_time = max(imu_df['datetime'].min(), ephys_df['datetime'].min()).to_pydatetime()\n",
    "end_time = min(imu_df['datetime'].max(), ephys_df['datetime'].max()).to_pydatetime()\n",
    "\n",
    "# Define notes to plot\n",
    "notes_to_plot = {\n",
    "    'exhalation_breath': 'depth'\n",
    "}\n",
    "\n",
    "plot_tag_data_interactive(data_pkl, imu_channels_to_plot, imu_sampling_rate=1, ephys_channels=ephys_channels_to_plot, \n",
    "                          imu_logger=imu_logger_to_use, ephys_logger=ephys_logger_to_use, note_annotations= notes_to_plot,\n",
    "                          time_range=(start_time, end_time), color_mapping_path=color_mapping_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import trimesh\n",
    "import numpy as np\n",
    "from pythreejs import *\n",
    "from IPython.display import display\n",
    "\n",
    "# Define the path to the OBJ file\n",
    "model_path = os.path.join(data_dir, '6_killerWhale_v017_LP.obj')\n",
    "\n",
    "# Load the OBJ file using Trimesh\n",
    "mesh = trimesh.load(model_path)\n",
    "\n",
    "# Extract vertices and faces from the mesh\n",
    "vertices = mesh.vertices\n",
    "faces = mesh.faces.astype(np.uint32)  # Ensure the indices are unsigned integers\n",
    "\n",
    "# Create BufferGeometry for PyThreeJS\n",
    "geometry = BufferGeometry(\n",
    "    attributes={\n",
    "        'position': BufferAttribute(vertices, normalized=False),\n",
    "        'index': BufferAttribute(faces.flatten(), normalized=False)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create a material\n",
    "material = MeshLambertMaterial(color='red') # , roughness=0.9, metalness=0.2\n",
    "key_light = DirectionalLight(color='white', position=[3, 5, 1], intensity=0.75)\n",
    "\n",
    "# Create the Mesh\n",
    "mesh = Mesh(geometry=geometry, material=material, position=[0, 0, 200], rotation= [0, math.pi, 0, 'XYZ'])\n",
    "\n",
    "# Move (translate) the mesh\n",
    "mesh.position = [0, 0, 200]  # Move the mesh up by 1 unit on the Y-axis\n",
    "\n",
    "# Rotate the mesh\n",
    "#mesh.rotation = [0.5, 0.5, 0, 0]  # Rotate the mesh around the X and Y axes (in radians)\n",
    "\n",
    "# Scale the mesh\n",
    "mesh.scale = [1.5, 1.5, 1.5]  # Scale the mesh uniformly by 1.5 on all axes\n",
    "\n",
    "# Create a scene, camera, and renderer\n",
    "scene = Scene(children=[mesh, AmbientLight(color='#ffffff', intensity=0.5)])\n",
    "camera = PerspectiveCamera(position=[0, 0, 5], up=[0, 1, 0], children=[key_light])\n",
    "renderer = Renderer(camera=camera, scene=scene, controls=[OrbitControls(controlling=camera)], width=400, height=400)\n",
    "\n",
    "# Display the model in the notebook\n",
    "display(renderer)\n",
    "\n",
    "ball = Mesh(geometry=SphereGeometry(), \n",
    "            material=MeshLambertMaterial(color='red'))\n",
    "\n",
    "\n",
    "c = PerspectiveCamera(position=[0, 5, 5], up=[0, 1, 0], children=[key_light])\n",
    "\n",
    "scene = Scene(children=[ball, c, AmbientLight(color='#777777')], background=None)\n",
    "\n",
    "renderer = Renderer(camera=c, \n",
    "                    scene=scene,\n",
    "                    alpha=True,\n",
    "                    clearOpacity=0,\n",
    "                    controls=[OrbitControls(controlling=c)])\n",
    "display(renderer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pkl.info['UF-01']['datetime_metadata']['fs']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finescale_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
