{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag to animal frame: re-orienting tag to match animal's axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a tutorial my friend Max developed to help with this headache: https://flukeandfeather.com/posts/2024-08-30-animal-orientation-with-imu-ta/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect data\n",
    "Load pickle file and inspect contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Import necessary pyologger utilities\n",
    "from pyologger.load_data.datareader import DataReader\n",
    "from pyologger.load_data.metadata import Metadata\n",
    "from pyologger.plot_data.plotter import *\n",
    "from pyologger.process_data.sampling import upsample\n",
    "from pyologger.calibrate_data.zoc import *\n",
    "from pyologger.plot_data.plotter import plot_depth_correction\n",
    "from pyologger.calibrate_data.calibrate_acc_mag import *\n",
    "\n",
    "# Change the current working directory to the root directory\n",
    "# os.chdir(\"/Users/fbar/Documents/GitHub/pyologger\")\n",
    "os.chdir(\"/Users/jessiekb/Documents/GitHub/pyologger\")\n",
    "\n",
    "root_dir = os.getcwd()\n",
    "data_dir = os.path.join(root_dir, \"data\")\n",
    "color_mapping_path = os.path.join(root_dir, \"color_mappings.json\")\n",
    "\n",
    "# Verify the current working directory\n",
    "print(f\"Current working directory: {root_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the info class\n",
    "metadata = Metadata()\n",
    "metadata.fetch_databases(verbose=False)\n",
    "\n",
    "# Save databases\n",
    "dep_db = metadata.get_metadata(\"dep_DB\")\n",
    "logger_db = metadata.get_metadata(\"logger_DB\")\n",
    "rec_db = metadata.get_metadata(\"rec_DB\")\n",
    "animal_db = metadata.get_metadata(\"animal_DB\")\n",
    "\n",
    "# Assuming you have the metadata and dep_db loaded:\n",
    "datareader = DataReader()\n",
    "deployment_folder = datareader.check_deployment_folder(dep_db, data_dir)\n",
    "\n",
    "if deployment_folder:\n",
    "    datareader.read_files(metadata, save_csv=True, save_parq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data_reader object from the pickle file\n",
    "pkl_path = os.path.join(deployment_folder, 'outputs', 'data.pkl')\n",
    "\n",
    "with open(pkl_path, 'rb') as file:\n",
    "    data_pkl = pickle.load(file)\n",
    "\n",
    "for logger_id, info in data_pkl.info.items():\n",
    "    sampling_frequency = info.get('datetime_metadata', {}).get('fs', None)\n",
    "    if sampling_frequency is not None:\n",
    "        # Format the sampling frequency to 5 significant digits\n",
    "        print(f\"Sampling frequency for {logger_id}: {sampling_frequency} Hz\")\n",
    "    else:\n",
    "        print(f\"No sampling frequency available for {logger_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change out preferred source of IMU or ephys data depending on your deployment\n",
    "imu_logger = 'CC-96'\n",
    "ephys_logger = 'UF-01'\n",
    "\n",
    "acc_data = np.vstack((data_pkl.data[imu_logger]['accX_adjusted'].values, \n",
    "                              data_pkl.data[imu_logger]['accY_adjusted'].values, \n",
    "                              data_pkl.data[imu_logger]['accZ_adjusted'].values)).T\n",
    "mag_data = np.vstack((data_pkl.data[imu_logger]['magX_adjusted'].values, \n",
    "                        data_pkl.data[imu_logger]['magY_adjusted'].values, \n",
    "                        data_pkl.data[imu_logger]['magZ_adjusted'].values)).T\n",
    "gyr_data = np.vstack((data_pkl.data[imu_logger]['gyrX'].values, \n",
    "                        data_pkl.data[imu_logger]['gyrY'].values, \n",
    "                        data_pkl.data[imu_logger]['gyrZ'].values)).T\n",
    "\n",
    "# # First, check if corrected accelerometer data exists\n",
    "# if 'corr_accX' in data_pkl.data[imu_logger].columns:\n",
    "#     print(\"Corrected accelerometer data ('corr_accX', 'corr_accY', 'corr_accZ') is available. No further adjustments needed.\")\n",
    "# else:\n",
    "#     # If corrected data does not exist, check if adjusted accelerometer data exists\n",
    "#     if 'accX_adjusted' in data_pkl.data[imu_logger].columns and 'magX_adjusted' in data_pkl.data[imu_logger].columns:\n",
    "#         # Use adjusted accelerometer data\n",
    "#         acc_data = np.vstack((data_pkl.data[imu_logger]['accX_adjusted'].values, \n",
    "#                               data_pkl.data[imu_logger]['accY_adjusted'].values, \n",
    "#                               data_pkl.data[imu_logger]['accZ_adjusted'].values)).T\n",
    "#         mag_data = np.vstack((data_pkl.data[imu_logger]['magX_adjusted'].values, \n",
    "#                               data_pkl.data[imu_logger]['magY_adjusted'].values, \n",
    "#                               data_pkl.data[imu_logger]['magZ_adjusted'].values)).T\n",
    "#         gyr_data = np.vstack((data_pkl.data[imu_logger]['gyrX'].values, \n",
    "#                               data_pkl.data[imu_logger]['gyrY'].values, \n",
    "#                               data_pkl.data[imu_logger]['gyrZ'].values)).T\n",
    "#         print(\"Using calibrated accelerometer and magnetometer values from Step 2.\")\n",
    "#     else:\n",
    "#         # Throw a warning and use raw accelerometer data\n",
    "#         print(\"Warning: Accelerometer values have not yet been adjusted. Check Step 2: Calibrating accelerometer and magnetometer. Using raw accelerometer values (accX, accY, accZ) instead.\")\n",
    "#         acc_data = np.vstack((data_pkl.data[imu_logger]['accX'].values, \n",
    "#                               data_pkl.data[imu_logger]['accY'].values, \n",
    "#                               data_pkl.data[imu_logger]['accZ'].values)).T\n",
    "#         mag_data = np.vstack((data_pkl.data[imu_logger]['magX'].values, \n",
    "#                               data_pkl.data[imu_logger]['magY'].values, \n",
    "#                               data_pkl.data[imu_logger]['magZ'].values)).T\n",
    "#         gyr_data = np.vstack((data_pkl.data[imu_logger]['gyrX'].values, \n",
    "#                               data_pkl.data[imu_logger]['gyrY'].values, \n",
    "#                               data_pkl.data[imu_logger]['gyrZ'].values)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from magnetic_field_calculator import MagneticFieldCalculator\n",
    "\n",
    "def orientation_and_heading_correction(abar0, acc_data, mag_data, gyr_data=None):\n",
    "    \"\"\"\n",
    "    Corrects the orientation and heading of tag data to align with the reference frame of an animal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    abar0 : array_like\n",
    "        A 3-element vector representing the accelerometer readings when the animal is stationary on its belly.\n",
    "    acc_data : array_like\n",
    "        A 2D array where each row represents a 3-element accelerometer reading.\n",
    "    mag_data : array_like\n",
    "        A 2D array where each row represents a 3-element magnetometer reading.\n",
    "    gyr_data : array_like, optional\n",
    "        A 2D array where each row represents a 3-element gyroscope reading. If provided, gyroscope data will also be corrected.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pitch_deg : array_like\n",
    "        The pitch angles in degrees for the entire dataset.\n",
    "    roll_deg : array_like\n",
    "        The roll angles in degrees for the entire dataset.\n",
    "    heading_deg : array_like\n",
    "        The heading angles in degrees for the entire dataset.\n",
    "    acc_corr : array_like\n",
    "        The corrected accelerometer data.\n",
    "    mag_corr : array_like\n",
    "        The corrected magnetometer data.\n",
    "    gyr_corr : array_like, optional\n",
    "        The corrected gyroscope data. Only returned if gyr_data is provided.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function seeks to rotate tag data to the reference frame of an animal.\n",
    "    The function first normalizes the provided stationary accelerometer vector, computes the pitch and roll angles,\n",
    "    and then applies the corresponding rotation matrices to correct the input accelerometer, magnetometer, and optionally,\n",
    "    gyroscope data. The function returns the corrected orientation in terms of pitch, roll, and heading angles.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> abar0 = np.array([0.1, 0.2, -0.98])\n",
    "    >>> acc_data = np.random.rand(100, 3)\n",
    "    >>> mag_data = np.random.rand(100, 3)\n",
    "    >>> pitch_deg, roll_deg, heading_deg, acc_corr, mag_corr = orientation_and_heading_correction(abar0, acc_data, mag_data)\n",
    "    >>> pitch_deg, roll_deg, heading_deg, acc_corr, mag_corr, gyr_corr = orientation_and_heading_correction(abar0, acc_data, mag_data, gyr_data=np.random.rand(100, 3))\n",
    "    \"\"\"\n",
    "    # Normalize abar0 to create abar\n",
    "    abar = abar0 / np.linalg.norm(abar0)\n",
    "    \n",
    "    # Calculate initial pitch (p0) and roll (r0)\n",
    "    p0 = -np.arcsin(abar[0])\n",
    "    r0 = np.arctan2(abar[1], abar[2])\n",
    "    # Constrain p to [-pi / 2, pi / 2]\n",
    "    if p0 > np.pi / 2:\n",
    "        p0 = np.pi / 2 - p0\n",
    "        r0 = r0 + np.pi\n",
    "\n",
    "    # Define rotation matrices for pitch and roll\n",
    "    def rotP(p):\n",
    "        return np.array([[np.cos(p), 0, np.sin(p)],\n",
    "                         [0, 1, 0],\n",
    "                         [-np.sin(p), 0, np.cos(p)]])\n",
    "    \n",
    "    def rotR(r):\n",
    "        return np.array([[1, 0, 0],\n",
    "                         [0, np.cos(r), -np.sin(r)],\n",
    "                         [0, np.sin(r), np.cos(r)]])\n",
    "    \n",
    "    # Calculate rotation matrix W\n",
    "    W = np.matmul(rotP(p0), rotR(r0)).T\n",
    "\n",
    "    # Correct the accelerometer and magnetometer data for the entire dataset\n",
    "    acc_corr = np.matmul(acc_data, W)\n",
    "    mag_corr = np.matmul(mag_data, W)\n",
    "    \n",
    "    # Correct the gyroscope data if provided\n",
    "    if gyr_data is not None:\n",
    "        gyr_corr = np.matmul(gyr_data, W)\n",
    "    else:\n",
    "        gyr_corr = None\n",
    "    \n",
    "    # Calculate magnitude of the corrected accelerometer vectors\n",
    "    A = np.linalg.norm(acc_corr, axis=1)\n",
    "    \n",
    "    # Calculate pitch and roll in degrees from corrected accelerometer data\n",
    "    pitch_deg = -np.degrees(np.arcsin(acc_corr[:, 0] / A))\n",
    "    roll_deg = np.degrees(np.arctan2(acc_corr[:, 1], acc_corr[:, 2]))\n",
    "    \n",
    "    #mag_horiz = np.matmul(np.matmul(mag_corr, rotR(np.deg2rad(roll_deg)).T), rotP(np.deg2rad(pitch_deg)).T) # gimbaling by applying 1. un-roll and then 2. un-pitch\n",
    "    # Initialize an array to hold the gimbaled magnetic data\n",
    "    mag_horiz = np.zeros_like(mag_corr)\n",
    "    \n",
    "    # Apply the un-roll and un-pitch rotation for each time step\n",
    "    for i in range(len(pitch_deg)):\n",
    "        mag_horiz[i, :] = np.matmul(np.matmul(mag_corr[i, :], rotR(np.deg2rad(roll_deg[i])).T), rotP(np.deg2rad(pitch_deg[i])).T)\n",
    "\n",
    "    latitude = 32.764567  # Example latitude\n",
    "    longitude = -117.228665  # Example longitude\n",
    "\n",
    "    # Get the declination using MagneticFieldCalculator\n",
    "    calculator = MagneticFieldCalculator()\n",
    "    result = calculator.calculate(latitude=latitude, longitude=longitude)\n",
    "    declination = result['field-value']['declination']\n",
    "\n",
    "    print(f\"The declination at latitude {latitude} and longitude {longitude} is {declination} degrees.\")\n",
    "    # Calculate heading in degrees from corrected magnetometer data\n",
    "    heading_deg = np.degrees(np.arctan2(mag_horiz[:, 1], mag_horiz[:, 0])) + declination['value']\n",
    "    \n",
    "    # Return the corrected pitch, roll, and heading for the entire dataset\n",
    "    if gyr_corr is not None:\n",
    "        return pitch_deg, roll_deg, heading_deg, acc_corr, mag_corr, gyr_corr\n",
    "    else:\n",
    "        return pitch_deg, roll_deg, heading_deg, acc_corr, mag_corr\n",
    "\n",
    "abar0 = [0, 0, -9.8]\n",
    "# Use the function to get corrected orientation and heading for the entire dataset\n",
    "pitch_deg, roll_deg, heading_deg, acc_corr, mag_corr, gyr_corr = orientation_and_heading_correction(\n",
    "    abar0, \n",
    "    acc_data=acc_data, \n",
    "    mag_data=mag_data, \n",
    "    gyr_data=gyr_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(gyr_corr)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Gyroscope Data')\n",
    "plt.title('Gyroscope Data Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pkl.info[imu_logger]['channelinfo']['accX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_pkl.data[imu_logger][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_corr[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metadata for the corrected channels\n",
    "# Define the metadata for the corrected channels\n",
    "corrected_channels = ['corr_accX', 'corr_accY', 'corr_accZ', \n",
    "                      'corr_magX', 'corr_magY', 'corr_magZ', \n",
    "                      'corr_gyrX', 'corr_gyrY', 'corr_gyrZ', \n",
    "                      'pitch', 'roll', 'heading']\n",
    "\n",
    "# Loop through the corrected channels and add the corrected data and metadata\n",
    "for channel in corrected_channels:\n",
    "    if 'corr_acc' in channel:\n",
    "        index = ['corr_accX', 'corr_accY', 'corr_accZ'].index(channel)\n",
    "        data_pkl.data[imu_logger][channel] = acc_corr[:, index]\n",
    "        # Dynamically update the metadata\n",
    "        data_pkl.info[imu_logger]['channelinfo'][channel] = {\n",
    "            'original_name': f\"Corrected {data_pkl.info[imu_logger]['channelinfo'][channel.replace('corr_', '')]['original_name']}\",\n",
    "            'unit': data_pkl.info[imu_logger]['channelinfo'][channel.replace('corr_', '')]['unit']\n",
    "        }\n",
    "    elif 'corr_mag' in channel:\n",
    "        index = ['corr_magX', 'corr_magY', 'corr_magZ'].index(channel)\n",
    "        data_pkl.data[imu_logger][channel] = mag_corr[:, index]\n",
    "        # Dynamically update the metadata\n",
    "        data_pkl.info[imu_logger]['channelinfo'][channel] = {\n",
    "            'original_name': f\"Corrected {data_pkl.info[imu_logger]['channelinfo'][channel.replace('corr_', '')]['original_name']}\",\n",
    "            'unit': data_pkl.info[imu_logger]['channelinfo'][channel.replace('corr_', '')]['unit']\n",
    "        }\n",
    "    elif 'corr_gyr' in channel:\n",
    "        index = ['corr_gyrX', 'corr_gyrY', 'corr_gyrZ'].index(channel)\n",
    "        data_pkl.data[imu_logger][channel] = gyr_corr[:, index]\n",
    "        # Dynamically update the metadata\n",
    "        data_pkl.info[imu_logger]['channelinfo'][channel] = {\n",
    "            'original_name': f\"Corrected {data_pkl.info[imu_logger]['channelinfo'][channel.replace('corr_', '')]['original_name']}\",\n",
    "            'unit': data_pkl.info[imu_logger]['channelinfo'][channel.replace('corr_', '')]['unit']\n",
    "        }\n",
    "    elif channel == 'pitch':\n",
    "        data_pkl.data[imu_logger][channel] = pitch_deg\n",
    "        data_pkl.info[imu_logger]['channelinfo'][channel] = {\n",
    "            'original_name': 'Pitch [degrees]',\n",
    "            'unit': 'degrees'\n",
    "        }\n",
    "    elif channel == 'roll':\n",
    "        data_pkl.data[imu_logger][channel] = roll_deg\n",
    "        data_pkl.info[imu_logger]['channelinfo'][channel] = {\n",
    "            'original_name': 'Roll [degrees]',\n",
    "            'unit': 'degrees'\n",
    "        }\n",
    "    elif channel == 'heading':\n",
    "        data_pkl.data[imu_logger][channel] = heading_deg\n",
    "        data_pkl.info[imu_logger]['channelinfo'][channel] = {\n",
    "            'original_name': 'Heading [degrees]',\n",
    "            'unit': 'degrees'\n",
    "        }\n",
    "\n",
    "imu_channels_to_plot = ['depth', \n",
    "                        'accX', 'accY', 'accZ', \n",
    "                        'corr_accX', 'corr_accY', 'corr_accZ', \n",
    "                        'gyrX', 'gyrY', 'gyrZ', \n",
    "                        'corr_gyrX', 'corr_gyrY', 'corr_gyrZ', \n",
    "                        'corr_magX', 'corr_magY', 'corr_magZ', \n",
    "                        'pitch', 'roll', 'heading']\n",
    "ephys_channels_to_plot = []\n",
    "imu_logger_to_use = imu_logger\n",
    "ephys_logger_to_use = ephys_logger\n",
    "\n",
    "# Get the overlapping time range\n",
    "imu_df = data_pkl.data[imu_logger_to_use]\n",
    "ephys_df = data_pkl.data[ephys_logger_to_use]\n",
    "start_time = max(imu_df['datetime'].min(), ephys_df['datetime'].min()).to_pydatetime()\n",
    "end_time = min(imu_df['datetime'].max(), ephys_df['datetime'].max()).to_pydatetime()\n",
    "\n",
    "# Define notes to plot\n",
    "notes_to_plot = {\n",
    "    'exhalation_breath': 'depth'\n",
    "}\n",
    "\n",
    "plot_tag_data_interactive2(data_pkl, imu_channels_to_plot, imu_sampling_rate=5, ephys_channels=ephys_channels_to_plot, \n",
    "                          imu_logger=imu_logger_to_use, ephys_logger=ephys_logger_to_use, note_annotations= notes_to_plot,\n",
    "                          time_range=(start_time, end_time), color_mapping_path=color_mapping_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: save new pickle file\n",
    "\n",
    "with open(pkl_path, 'wb') as file:\n",
    "        pickle.dump(data_pkl, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN PROGRESS, NOT WORKING YET\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_acc_for_exhalation_breaths(data_pkl):\n",
    "    \"\"\"\n",
    "    Plot accX, accY, and accZ values for each exhalation breath event and \n",
    "    return the average acceleration vector (abar0) around the events.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_pkl : object\n",
    "        The structured data object containing sensor data and notes_df.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    abar0 : numpy.ndarray\n",
    "        A vector containing the mean of accX, accY, and accZ during the 10 seconds \n",
    "        surrounding each exhalation breath event.\n",
    "    \"\"\"\n",
    "    # Extract the relevant accelerometer data\n",
    "    accX = data_pkl.data['CC-96']['accX'].values\n",
    "    accY = data_pkl.data['CC-96']['accY'].values\n",
    "    accZ = data_pkl.data['CC-96']['accZ'].values\n",
    "    datetime_data = data_pkl.data['CC-96']['datetime'].values\n",
    "\n",
    "    # Convert datetime_data to numpy.datetime64 for proper subtraction\n",
    "    datetime_data = np.array(datetime_data, dtype='datetime64[ns]')\n",
    "\n",
    "    # Filter the notes_df for 'exhalation_breath' events\n",
    "    breath_events = data_pkl.notes_df[data_pkl.notes_df['key'] == 'exhalation_breath']\n",
    "\n",
    "    # Initialize lists to store the surrounding data\n",
    "    accX_segments = []\n",
    "    accY_segments = []\n",
    "    accZ_segments = []\n",
    "\n",
    "    # Plot the accelerometer data for each breath event\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    for _, event in breath_events.iterrows():\n",
    "        event_time = event['datetime']  # Convert event_time to numpy.datetime64\n",
    "\n",
    "        # Round to the nearest second\n",
    "        event_time_rounded = event_time.round('1s')\n",
    "\n",
    "        # Find the index of the rounded event time\n",
    "        rounded_time_index = datetime_data.tolist().index(event_time_rounded)\n",
    "\n",
    "        # Define the window of ±5 seconds around the breath event\n",
    "        time_window = int(5 * data_pkl.info['CC-96']['datetime_metadata']['fs'])\n",
    "        start_index = max(rounded_time_index - time_window, 0)\n",
    "        end_index = min(rounded_time_index + time_window, len(datetime_data))\n",
    "\n",
    "        # Extract the segments\n",
    "        accX_segment = accX[start_index:end_index]\n",
    "        accY_segment = accY[start_index:end_index]\n",
    "        accZ_segment = accZ[start_index:end_index]\n",
    "        time_segment = datetime_data[start_index:end_index]\n",
    "\n",
    "        # Append to lists\n",
    "        accX_segments.append(accX_segment)\n",
    "        accY_segments.append(accY_segment)\n",
    "        accZ_segments.append(accZ_segment)\n",
    "\n",
    "        # Plot accX, accY, and accZ around the breath event\n",
    "        plt.plot(time_segment, accX_segment, label='accX', color='blue', alpha=0.5)\n",
    "        plt.plot(time_segment, accY_segment, label='accY', color='green', alpha=0.5)\n",
    "        plt.plot(time_segment, accZ_segment, label='accZ', color='red', alpha=0.5)\n",
    "\n",
    "        # Highlight the breath event\n",
    "        plt.axvline(datetime_data[closest_time_index], color='black', linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.xlabel('Datetime')\n",
    "    plt.ylabel('Acceleration (g)')\n",
    "    plt.title('Accelerometer Data (accX, accY, accZ) During Exhalation Breaths')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate the mean vector abar0\n",
    "    mean_accX = np.mean(np.concatenate(accX_segments))\n",
    "    mean_accY = np.mean(np.concatenate(accY_segments))\n",
    "    mean_accZ = np.mean(np.concatenate(accZ_segments))\n",
    "    abar0 = np.array([mean_accX, mean_accY, mean_accZ])\n",
    "\n",
    "    return abar0\n",
    "\n",
    "# Example usage (doesn't work currently)\n",
    "#abar0 = plot_acc_for_exhalation_breaths(data_pkl)\n",
    "#print(\"Average acceleration vector (abar0):\", abar0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finescale_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
