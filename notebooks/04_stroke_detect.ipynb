{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stroke detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect data\n",
    "Load pickle file and inspect contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary pyologger utilities\n",
    "from pyologger.utils.folder_manager import *\n",
    "from pyologger.utils.event_manager import *\n",
    "from pyologger.plot_data.plotter import *\n",
    "from pyologger.io_operations.base_exporter import *\n",
    "from pyologger.utils.data_manager import *\n",
    "from pyologger.process_data.peak_detect import *\n",
    "from pyologger.process_data.odba import *\n",
    "\n",
    "# Load important file paths and configurations\n",
    "config, data_dir, color_mapping_path, channel_mapping_path = load_configuration()\n",
    "# Streamlit load data\n",
    "animal_id, dataset_id, deployment_id, dataset_folder, deployment_folder, data_pkl, config_manager = select_and_load_deployment(data_dir, dataset_id=\"oror-adult-orca_hr-sr-vid_sw_JKB-PP\", deployment_id=\"2024-01-16_oror-002\")\n",
    "pkl_path = os.path.join(deployment_folder, 'outputs', 'data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_processing_step = \"Processing Step 04 IN PROGRESS.\"\n",
    "config_manager.add_to_config(\"current_processing_step\", current_processing_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve relevant configuration settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve values from config\n",
    "variables = [\"calm_horizontal_start_time\", \"calm_horizontal_end_time\", \n",
    "             \"zoom_window_start_time\", \"zoom_window_end_time\", \n",
    "             \"overlap_start_time\", \"overlap_end_time\"]\n",
    "settings = config_manager.get_from_config(variables, section=\"settings\")\n",
    "\n",
    "# Assign retrieved values to variables\n",
    "CALM_HORIZONTAL_START_TIME = settings.get(\"calm_horizontal_start_time\")\n",
    "CALM_HORIZONTAL_END_TIME = settings.get(\"calm_horizontal_end_time\")\n",
    "ZOOM_START_TIME = settings.get(\"zoom_window_start_time\")\n",
    "ZOOM_END_TIME = settings.get(\"zoom_window_end_time\")\n",
    "OVERLAP_START_TIME = settings.get(\"overlap_start_time\")\n",
    "OVERLAP_END_TIME = settings.get(\"overlap_end_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find time chunk when stroking is dominant activity\n",
    "Use interactive plot to locate a start time and end time when stroking is the dominant activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SAMPLING_RATE = 10\n",
    "\n",
    "notes_to_plot = {\n",
    "    'heartbeat_manual_ok': {'signal': 'ecg', 'symbol': 'triangle-down', 'color': 'blue'},\n",
    "    'heartbeat_auto_detect_accepted': {'signal': 'ecg', 'symbol': 'triangle-up', 'color': 'green'},\n",
    "    'heartbeat_auto_detect_rejected': {'signal': 'ecg', 'symbol': 'triangle-up', 'color': 'red'}\n",
    "}\n",
    "\n",
    "fig = plot_tag_data_interactive(\n",
    "    data_pkl=data_pkl,\n",
    "    sensors=['ecg'],\n",
    "    derived_data_signals=['depth', 'corrected_acc', 'corrected_gyr', 'prh'],\n",
    "    channels={},\n",
    "    time_range=(OVERLAP_START_TIME, OVERLAP_END_TIME),\n",
    "    note_annotations=notes_to_plot,\n",
    "    color_mapping_path=color_mapping_path,\n",
    "    target_sampling_rate=TARGET_SAMPLING_RATE,\n",
    "    zoom_start_time=ZOOM_START_TIME,\n",
    "    zoom_end_time=ZOOM_END_TIME,\n",
    "    zoom_range_selector_channel='depth',\n",
    "    plot_event_values=[],\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve timezone from deployment info\n",
    "timezone = data_pkl.deployment_info['Time Zone']\n",
    "\n",
    "# Define placeholder timestamps for calm period in the retrieved timezone\n",
    "stroking_start_time = pd.Timestamp(\"2024-01-16 10:03:10\").tz_localize(timezone)\n",
    "stroking_end_time = pd.Timestamp(\"2024-01-16 10:03:40\").tz_localize(timezone)\n",
    "\n",
    "# Use ConfigManager to add both stroking start and end times to the config in the desired section\n",
    "config_manager.add_to_config(\n",
    "    entries={\n",
    "        \"stroking_start_time\": str(stroking_start_time),\n",
    "        \"stroking_end_time\": str(stroking_end_time)\n",
    "    },\n",
    "    section=\"settings\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE AS NEEDED\n",
    "\n",
    "detection_mode=\"stroke_rate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parent signal options\n",
    "parent_signal_options = list(data_pkl.sensor_data.keys()) + list(data_pkl.derived_data.keys())\n",
    "default_parent_signal = \"ecg\" if detection_mode == \"heart_rate\" else \"corrected_gyr\"\n",
    "\n",
    "# User input for parent signal\n",
    "print(f\"Available parent signals: {parent_signal_options}\")\n",
    "parent_signal = input(f\"Choose parent signal (default: {default_parent_signal}): \").strip()\n",
    "if not parent_signal or parent_signal not in parent_signal_options:\n",
    "    parent_signal = default_parent_signal\n",
    "\n",
    "# Get available channels\n",
    "if parent_signal in data_pkl.sensor_data:\n",
    "    available_channels = list(data_pkl.sensor_data[parent_signal].columns)\n",
    "elif parent_signal in data_pkl.derived_data:\n",
    "    available_channels = list(data_pkl.derived_data[parent_signal].columns)\n",
    "else:\n",
    "    available_channels = []\n",
    "\n",
    "# Default channel\n",
    "default_channel = \"ecg\" if detection_mode == \"heart_rate\" else \"gy\"\n",
    "\n",
    "# User input for channel\n",
    "print(f\"Available channels: {available_channels}\")\n",
    "channel = input(f\"Choose channel (default: {default_channel}): \").strip()\n",
    "if not channel or channel not in available_channels:\n",
    "    channel = default_channel\n",
    "\n",
    "# Configure signals\n",
    "signal_df = data_pkl.sensor_data[parent_signal] if parent_signal in data_pkl.sensor_data else data_pkl.derived_data[parent_signal]\n",
    "signal = data_pkl.sensor_data[parent_signal][channel] if parent_signal in data_pkl.sensor_data else data_pkl.derived_data[parent_signal][channel]\n",
    "datetime_signal = data_pkl.sensor_data[parent_signal]['datetime'] if parent_signal in data_pkl.sensor_data else data_pkl.derived_data[parent_signal]['datetime']\n",
    "sampling_rate = data_pkl.sensor_info.get(parent_signal, {}).get('sampling_frequency', calculate_sampling_frequency(datetime_signal))\n",
    "\n",
    "# Define the default time range based on the signal's datetime column\n",
    "signal_start = datetime_signal.min()\n",
    "signal_end = datetime_signal.max()\n",
    "\n",
    "# User input for time range\n",
    "print(f\"Signal time range: {signal_start} to {signal_end}\")\n",
    "start_time_input = input(f\"Enter start time (default: {signal_start}): \").strip()\n",
    "end_time_input = input(f\"Enter end time (default: {signal_end}): \").strip()\n",
    "\n",
    "# Determine time range based on user input\n",
    "start_datetime = pd.Timestamp(start_time_input) if start_time_input else signal_start\n",
    "end_datetime = pd.Timestamp(end_time_input) if end_time_input else signal_end\n",
    "\n",
    "# Filter signal based on the selected time range\n",
    "time_mask = (datetime_signal >= start_datetime) & (datetime_signal <= end_datetime)\n",
    "signal_subset = signal[time_mask]\n",
    "datetime_subset = datetime_signal[time_mask]\n",
    "signal_subset_df = signal_df[\n",
    "    (signal_df['datetime'] >= start_datetime) & \n",
    "    (signal_df['datetime'] <= end_datetime)\n",
    "]\n",
    "\n",
    "# Output the results\n",
    "print(f\"Time range selected: {start_datetime} to {end_datetime}\")\n",
    "print(f\"Signal subset size: {len(signal_subset)}\")\n",
    "\n",
    "# Retrieve parameters for peak detection\n",
    "params = config_manager.get_from_config(\n",
    "    variable_names=[\n",
    "        \"BROAD_LOW_CUTOFF\", \"BROAD_HIGH_CUTOFF\", \"NARROW_LOW_CUTOFF\", \"NARROW_HIGH_CUTOFF\",\n",
    "        \"FILTER_ORDER\", \"SPIKE_THRESHOLD\", \"SMOOTH_SEC_MULTIPLIER\", \"WINDOW_SIZE_MULTIPLIER\",\n",
    "        \"NORMALIZATION_NOISE\", \"PEAK_HEIGHT\", \"PEAK_DISTANCE_SEC\", \"SEARCH_RADIUS_SEC\",\n",
    "        \"MIN_PEAK_HEIGHT\", \"MAX_PEAK_HEIGHT\", \"enable_bandpass\", \"enable_spike_removal\",\n",
    "        \"enable_absolute\", \"enable_smoothing\", \"enable_normalization\", \"enable_refinement\"\n",
    "    ],\n",
    "    section=\"hr_peak_detection_settings\" if detection_mode == \"Heart Rate\" else \"stroke_peak_detection_settings\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite=False # If needed, change to true and rewrite settings here\n",
    "\n",
    "# Add parameters to the config file (if not already present)\n",
    "if overwrite | any(value is None for value in params.values()):\n",
    "    # Define default parameters for peak detection with simple structure (no descriptions here)\n",
    "    params = {\n",
    "        \"BROAD_LOW_CUTOFF\": 0.05,  # Hz, lower cutoff for the broad bandpass filter\n",
    "        \"BROAD_HIGH_CUTOFF\": 10,  # Hz, upper cutoff for the broad bandpass filter\n",
    "        \"NARROW_LOW_CUTOFF\": 0.1,  # Hz, lower cutoff for the narrow bandpass filter\n",
    "        \"NARROW_HIGH_CUTOFF\": 2.0,  # Hz, upper cutoff for the narrow bandpass filter\n",
    "        \"FILTER_ORDER\": 2,  # Order of the bandpass filter, affects sharpness\n",
    "        \"SPIKE_THRESHOLD\": 400,  # Threshold for removing large spikes (e.g., noise or artifacts)\n",
    "        \"SMOOTH_SEC_MULTIPLIER\": 0.41,  # Multiplier for calculating the smoothing window size (3 for HR)\n",
    "        \"WINDOW_SIZE_MULTIPLIER\": 15.5,  # Multiplier for calculating sliding window size (if this is too big it will lump all strokes into a plateau)\n",
    "        \"NORMALIZATION_NOISE\": 1e-10,  # Small constant to avoid division by zero in normalization\n",
    "        \"PEAK_HEIGHT\": -0.9,  # Minimum amplitude (height) for peak detection\n",
    "        \"PEAK_DISTANCE_SEC\": 0.5,  # Minimum time between detected peaks (in seconds)\n",
    "        \"SEARCH_RADIUS_SEC\": 0.3,  # Time range for refining the peak location (in seconds)\n",
    "        \"MIN_PEAK_HEIGHT\": 150,  # Minimum acceptable amplitude for detected peaks; original units\n",
    "        \"MAX_PEAK_HEIGHT\": 1000000,  # Maximum acceptable amplitude for detected peaks; original units \n",
    "        \"enable_bandpass\": True,  # Enable/disable bandpass filtering\n",
    "        \"enable_spike_removal\": False,  # Enable/disable spike removal\n",
    "        \"enable_absolute\": False,  # Enable/disable abs() transformation of signal (only use if HR, not for stroke rate)\n",
    "        \"enable_smoothing\": True,  # Enable/disable smoothing\n",
    "        \"enable_normalization\": True,  # Enable/disable sliding window normalization\n",
    "        \"enable_refinement\": True,  # Enable/disable peak refinement\n",
    "    }\n",
    "    config_manager.add_to_config(entries=params, section=\"stroke_peak_detection_settings\")\n",
    "else:\n",
    "    print(\"Settings loaded from config file, not overwritten.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run peak detection\n",
    "results = peak_detect(\n",
    "    signal=signal_subset,\n",
    "    sampling_rate=sampling_rate,\n",
    "    datetime_series=datetime_subset,\n",
    "    broad_lowcut=params[\"BROAD_LOW_CUTOFF\"],\n",
    "    broad_highcut=params[\"BROAD_HIGH_CUTOFF\"],\n",
    "    narrow_lowcut=params[\"NARROW_LOW_CUTOFF\"],\n",
    "    narrow_highcut=params[\"NARROW_HIGH_CUTOFF\"],\n",
    "    filter_order=params[\"FILTER_ORDER\"],\n",
    "    spike_threshold=params[\"SPIKE_THRESHOLD\"],\n",
    "    smooth_sec_multiplier=params[\"SMOOTH_SEC_MULTIPLIER\"],\n",
    "    window_size_multiplier=params[\"WINDOW_SIZE_MULTIPLIER\"],\n",
    "    normalization_noise=params[\"NORMALIZATION_NOISE\"],\n",
    "    peak_height=params[\"PEAK_HEIGHT\"],\n",
    "    peak_distance_sec=params[\"PEAK_DISTANCE_SEC\"],\n",
    "    search_radius_sec=params[\"SEARCH_RADIUS_SEC\"],\n",
    "    min_peak_height=params[\"MIN_PEAK_HEIGHT\"],\n",
    "    max_peak_height=params[\"MAX_PEAK_HEIGHT\"],\n",
    "    enable_bandpass=params[\"enable_bandpass\"],\n",
    "    enable_spike_removal=params[\"enable_spike_removal\"],\n",
    "    enable_absolute=params[\"enable_absolute\"],\n",
    "    enable_smoothing=params[\"enable_smoothing\"],\n",
    "    enable_normalization=params[\"enable_normalization\"],\n",
    "    enable_refinement=params[\"enable_refinement\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_rate(data_pkl, results, signal_subset_df, parent_signal,\n",
    "             params, sampling_rate, detection_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['peak_df']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use streamlit app to refine parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define peak detection parameters for stroke rate detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate stroke rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SAMPLING_RATE = 10\n",
    "\n",
    "notes_to_plot = {\n",
    "    'heartbeat_manual_ok': {'signal': 'ecg', 'symbol': 'triangle-down', 'color': 'blue'},\n",
    "    'heartbeat_auto_detect_accepted': {'signal': 'ecg', 'symbol': 'triangle-up', 'color': 'green'},\n",
    "    'heartbeat_auto_detect_rejected': {'signal': 'ecg', 'symbol': 'triangle-up', 'color': 'red'},\n",
    "    'strokebeat_auto_detect_accepted': {'signal': 'sr_narrow_bandpass', 'symbol': 'triangle-up', 'color': 'green'},\n",
    "    'strokebeat_auto_detect_rejected': {'signal': 'sr_narrow_bandpass', 'symbol': 'triangle-up', 'color': 'red'}\n",
    "}\n",
    "\n",
    "fig = plot_tag_data_interactive(\n",
    "    data_pkl=data_pkl,\n",
    "    sensors=['ecg', 'gyroscope'],\n",
    "    derived_data_signals=['depth', 'corrected_gyr', 'prh','stroke_rate', 'sr_broad_bandpass',\n",
    "                          'sr_narrow_bandpass', 'sr_smoothed',\n",
    "                          'sr_normalized'],\n",
    "    channels={}, #'corrected_gyr': ['broad_bandpassed_signal']\n",
    "    time_range=(OVERLAP_START_TIME, OVERLAP_END_TIME),\n",
    "    note_annotations=notes_to_plot,\n",
    "    color_mapping_path=color_mapping_path,\n",
    "    target_sampling_rate=TARGET_SAMPLING_RATE,\n",
    "    zoom_start_time=stroking_start_time,\n",
    "    zoom_end_time=stroking_end_time,\n",
    "    zoom_range_selector_channel='depth',\n",
    "    plot_event_values=[],\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data_pkl.derived_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the specified keys\n",
    "keys_to_remove = ['sr_broad_bandpass','sr_narrow_bandpass', 'sr_normalized']\n",
    "clear_intermediate_signals(data_pkl, remove_keys=keys_to_remove)\n",
    "\n",
    "initial_event_count = len(data_pkl.event_data)\n",
    "# Remove events with keys ending in '_rejected'\n",
    "data_pkl.event_data = data_pkl.event_data[~data_pkl.event_data['key'].str.endswith('_rejected', na=False)]\n",
    "# Get the final count of events\n",
    "final_event_count = len(data_pkl.event_data)\n",
    "# Print the number of removed events\n",
    "removed_event_count = initial_event_count - final_event_count\n",
    "print(f\"Removed {removed_event_count} events with keys ending in '_rejected'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get excerpt with stroking only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume the corrected accelerometer data is stored in data_pkl.derived_data['corrected_acc']\n",
    "corrected_acc = data_pkl.derived_data['corrected_acc']\n",
    "acc_sampling_rate = calculate_sampling_frequency(data_pkl.derived_data['corrected_acc']['datetime'])\n",
    "acc_sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_rate_subset = data_pkl.derived_data['stroke_rate'][\n",
    "        (data_pkl.derived_data['stroke_rate']['datetime'] >= stroking_start_time) &\n",
    "        (data_pkl.derived_data['stroke_rate']['datetime'] <= stroking_end_time)\n",
    "    ]\n",
    "\n",
    "# Calculate mean stroke rate\n",
    "mean_stroke_rate = stroke_rate_subset['stroke_rate'].mean()\n",
    "stroke_hz = mean_stroke_rate/60\n",
    "print(f'Stroke rate in Hz: {stroke_hz} Hz.')\n",
    "\n",
    "fh = stroke_hz / 2\n",
    "n = 4 * round(acc_sampling_rate / fh)\n",
    "\n",
    "# Calculate ODBA using VeDBA method with a window size of 5 samples\n",
    "odba_df = compute_odba(corrected_acc, fs=acc_sampling_rate, method='wilson', n=n)\n",
    "\n",
    "# Print the first few rows of the resulting ODBA DataFrame\n",
    "print(odba_df.head())\n",
    "\n",
    "# Optionally store it in derived_data\n",
    "data_pkl.derived_data['odba'] = odba_df\n",
    "data_pkl.derived_info['odba'] = {\n",
    "    \"channels\": [\"odba\"],\n",
    "    \"metadata\": {\n",
    "        \"odba\": {\"original_name\": \"Overall Dynamic Body Acceleration (VeDBA)\", \"unit\": \"g\"}\n",
    "    },\n",
    "    \"derived_from_sensors\": [\"corrected_acc\"],\n",
    "    \"transformation_log\": [\"VeDBA calculated with n=5\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SAMPLING_RATE = 10\n",
    "\n",
    "notes_to_plot = {\n",
    "    'heartbeat_manual_ok': {'signal': 'ecg', 'symbol': 'triangle-down', 'color': 'blue'},\n",
    "    'heartbeat_auto_detect_accepted': {'signal': 'ecg', 'symbol': 'triangle-up', 'color': 'green'},\n",
    "    'heartbeat_auto_detect_rejected': {'signal': 'ecg', 'symbol': 'triangle-up', 'color': 'red'},\n",
    "    'strokebeat_auto_detect_accepted': {'signal': 'sr_smoothed', 'symbol': 'triangle-up', 'color': 'green'},\n",
    "    'strokebeat_auto_detect_rejected': {'signal': 'sr_smoothed', 'symbol': 'triangle-up', 'color': 'red'}\n",
    "}\n",
    "\n",
    "fig = plot_tag_data_interactive(\n",
    "    data_pkl=data_pkl,\n",
    "    sensors=['ecg', 'gyroscope'],\n",
    "    derived_data_signals=['depth', 'corrected_gyr', 'prh', 'stroke_rate', 'sr_smoothed','odba'],\n",
    "    channels={}, #'corrected_gyr': ['broad_bandpassed_signal']\n",
    "    time_range=(OVERLAP_START_TIME, OVERLAP_END_TIME),\n",
    "    note_annotations=notes_to_plot,\n",
    "    color_mapping_path=color_mapping_path,\n",
    "    target_sampling_rate=TARGET_SAMPLING_RATE,\n",
    "    zoom_start_time=stroking_start_time,\n",
    "    zoom_end_time=stroking_end_time,\n",
    "    zoom_range_selector_channel='depth',\n",
    "    plot_event_values=[],\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_processing_step = \"Processing Step 04. Stroke rate and ODBA calculation complete.\"\n",
    "print(current_processing_step)\n",
    "\n",
    "# Add or update the current_processing_step for the specified deployment\n",
    "config_manager.add_to_config(\"current_processing_step\", current_processing_step)\n",
    "\n",
    "# Optional: save new pickle file\n",
    "with open(pkl_path, 'wb') as file:\n",
    "        pickle.dump(data_pkl, file)\n",
    "print(\"Pickle file updated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
