{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pipeline for DiveDB\n",
    "Uses classes `Metadata` and `DataReader` to facilitate data intake, processing, and alignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.10.4\n",
      "Current working directory: c:\\Users\\fbar\\Documents\\GitHub\\pyologger\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and set working directory (adjust to fit your preferences)\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "from notion_client import Client\n",
    "from dotenv import load_dotenv\n",
    "from datareader import DataReader\n",
    "from metadata import Metadata\n",
    "import plotly.express as px\n",
    "import pickle\n",
    "import nbformat\n",
    "print(nbformat.__version__)\n",
    "\n",
    "# Change the current working directory to the root directory\n",
    "os.chdir(\"/Users/fbar/Documents/GitHub/pyologger\")\n",
    "root_dir = os.getcwd()\n",
    "data_dir = os.path.join(root_dir, \"data\")\n",
    "\n",
    "# Verify the current working directory\n",
    "print(f\"Current working directory: {root_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query metadata\n",
    "Use Notion and [metadata entry form](https://forms.fillout.com/t/8UNuTLMaRfus) to start a recording and to generate identifiers for the Recording and Deployment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Notion secret token.\n",
      "Loaded database ID for dep_DB.\n",
      "Loaded database ID for rec_DB.\n",
      "Loaded database ID for logger_DB.\n",
      "Loaded database ID for animal_DB.\n",
      "Fetching data for dep_DB with ID 657cae511066439ea9499085e3443406\n",
      "Successfully fetched data for dep_DB.\n",
      "Fetching data for rec_DB with ID 0a86a1b1756c46afa84429e8ff13c79a\n",
      "Successfully fetched data for rec_DB.\n",
      "Fetching data for logger_DB with ID 8aa29755491c4357b87e43cb9a505a70\n",
      "Successfully fetched data for logger_DB.\n",
      "Fetching data for animal_DB with ID b57495033c4d4391aa5ab75de0291802\n",
      "Successfully fetched data for animal_DB.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Metadata class\n",
    "metadata = Metadata()\n",
    "metadata.fetch_databases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rec Date</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Animal</th>\n",
       "      <th>Start Time Precision</th>\n",
       "      <th>End Time</th>\n",
       "      <th>Actual Start Time</th>\n",
       "      <th>Time Zone</th>\n",
       "      <th>Start time</th>\n",
       "      <th>Deployment Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-06-19</td>\n",
       "      <td>Third day of deployments at SeaWorld with Cork...</td>\n",
       "      <td>orca</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>PST (Pacific Standard Time (UTC-7))</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-06-19_oror-001a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-06-18</td>\n",
       "      <td>Deployment second day at Sea World</td>\n",
       "      <td>orca</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>PST (Pacific Standard Time (UTC-7))</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-06-18_oror-001a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-06-17</td>\n",
       "      <td>ECG recordings with Ashley and Paul at SeaWorl...</td>\n",
       "      <td>orca</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>PST (Pacific Standard Time (UTC-7))</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-06-17_oror-002-001a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-16</td>\n",
       "      <td>Shuka ECG and CATS</td>\n",
       "      <td>orca</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>PST (Pacific Standard Time (UTC-7))</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-01-16_oror-002a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-06-06</td>\n",
       "      <td>Boat calibrations with Bill Hagey</td>\n",
       "      <td>boat</td>\n",
       "      <td>Approximative</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>PST (Pacific Standard Time (UTC-7))</td>\n",
       "      <td>09:31:30</td>\n",
       "      <td>2024-06-06_boat-001a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rec Date                                              Notes Animal  \\\n",
       "0  2024-06-19  Third day of deployments at SeaWorld with Cork...   orca   \n",
       "1  2024-06-18                 Deployment second day at Sea World   orca   \n",
       "2  2024-06-17  ECG recordings with Ashley and Paul at SeaWorl...   orca   \n",
       "3  2024-01-16                                 Shuka ECG and CATS   orca   \n",
       "4  2024-06-06                  Boat calibrations with Bill Hagey   boat   \n",
       "\n",
       "  Start Time Precision End Time Actual Start Time  \\\n",
       "0                 None     None              None   \n",
       "1                 None     None              None   \n",
       "2                 None     None              None   \n",
       "3                 None     None              None   \n",
       "4        Approximative     None              None   \n",
       "\n",
       "                             Time Zone Start time           Deployment Name  \n",
       "0  PST (Pacific Standard Time (UTC-7))       None      2024-06-19_oror-001a  \n",
       "1  PST (Pacific Standard Time (UTC-7))       None      2024-06-18_oror-001a  \n",
       "2  PST (Pacific Standard Time (UTC-7))       None  2024-06-17_oror-002-001a  \n",
       "3  PST (Pacific Standard Time (UTC-7))       None      2024-01-16_oror-002a  \n",
       "4  PST (Pacific Standard Time (UTC-7))   09:31:30      2024-06-06_boat-001a  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all deployments to identify deployment in question\n",
    "dep_db = metadata.get_metadata(\"dep_DB\")\n",
    "dep_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select a deployment\n",
    "Select a deployment by entering the index for the deployment in the table above that you would like to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please choose a deployment by selecting its index:\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Display relevant information to help the user decide\n",
    "print(\"Please choose a deployment by selecting its index:\")\n",
    "dep_db[['Deployment Name', 'Notes']]\n",
    "\n",
    "# Step 2: Prompt the user for input\n",
    "selected_index = int(input(\"Enter the index of the deployment you want to work with: \"))\n",
    "\n",
    "# Step 3: Process the user's selection\n",
    "if 0 <= selected_index < len(dep_db):\n",
    "    selected_deployment = dep_db.iloc[selected_index]\n",
    "    print(f\"You selected the deployment: {selected_deployment['Deployment Name']}\")\n",
    "    print(f\"Description: {selected_deployment['Notes']}\")\n",
    "else:\n",
    "    print(\"Invalid index selected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checks to see if folder exists\n",
    "Code searches for a folder with an exact match, also acceptable if a suffix has been added. Errors will be flagged if there is more than one folder matching deployment name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment folder path: c:\\Users\\fbar\\Documents\\GitHub\\Finescale-HR\\data\\2024-01-16_oror-002a\n",
      "Folder c:\\Users\\fbar\\Documents\\GitHub\\Finescale-HR\\data\\2024-01-16_oror-002a not found. Searching for folders with a similar name...\n",
      "Using the found folder: c:\\Users\\fbar\\Documents\\GitHub\\Finescale-HR\\data\\2024-01-16_oror-002a_Shuka-HR\n"
     ]
    }
   ],
   "source": [
    "# Get to deployment folder\n",
    "deployment_folder = os.path.join(data_dir, selected_deployment['Deployment Name'])\n",
    "\n",
    "# Verify the current working directory\n",
    "print(f\"Deployment folder path: {deployment_folder}\")\n",
    "\n",
    "# Step 1: Check if the folder exists\n",
    "if os.path.exists(deployment_folder):\n",
    "    print(f\"Deployment folder found: {deployment_folder}\")\n",
    "else:\n",
    "    # Step 2: If not found, search for a folder that starts with the deployment name\n",
    "    print(f\"Folder {deployment_folder} not found. Searching for folders with a similar name...\")\n",
    "    \n",
    "    # Get a list of all folders in the data directory\n",
    "    possible_folders = [folder for folder in os.listdir(data_dir) \n",
    "                        if folder.startswith(selected_deployment['Deployment Name'])]\n",
    "    \n",
    "    if len(possible_folders) == 1:\n",
    "        # If exactly one match is found, use that folder\n",
    "        deployment_folder = os.path.join(data_dir, possible_folders[0])\n",
    "        print(f\"Using the found folder: {deployment_folder}\")\n",
    "    elif len(possible_folders) > 1:\n",
    "        # If multiple matches are found, ask the user to select one\n",
    "        print(\"Multiple matching folders found. Please select one:\")\n",
    "        for i, folder in enumerate(possible_folders):\n",
    "            print(f\"{i}: {folder}\")\n",
    "        selected_index = int(input(\"Enter the index of the folder you want to use: \"))\n",
    "        if 0 <= selected_index < len(possible_folders):\n",
    "            deployment_folder = os.path.join(data_dir, possible_folders[selected_index])\n",
    "            print(f\"Using the selected folder: {deployment_folder}\")\n",
    "        else:\n",
    "            print(\"Invalid selection. Aborting.\")\n",
    "            deployment_folder = None\n",
    "    else:\n",
    "        # If no matches are found, return an error\n",
    "        print(\"Error: Folder not found.\")\n",
    "        deployment_folder = None\n",
    "\n",
    "# Continue processing if a valid folder was found\n",
    "if deployment_folder:\n",
    "    # Perform actions with the selected deployment folder\n",
    "    pass  # Replace with your processing logic\n",
    "else:\n",
    "    print(\"Processing aborted due to missing folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data\n",
    "Using `DataReader` class to query the files in the folder using logger IDs. Will flag unrecognized file types and summarize which loggers' data has been recognized. Will output copies of processed CSV data into an `outputs` folder that will be created within the original deployment folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment data folder: c:\\Users\\fbar\\Documents\\GitHub\\Finescale-HR\\data\\2024-01-16_oror-002a_Shuka-HR\n",
      "Fetching data for dep_DB with ID 657cae511066439ea9499085e3443406\n",
      "Successfully fetched data for dep_DB.\n",
      "Fetching data for rec_DB with ID 0a86a1b1756c46afa84429e8ff13c79a\n",
      "Successfully fetched data for rec_DB.\n",
      "Fetching data for logger_DB with ID 8aa29755491c4357b87e43cb9a505a70\n",
      "Successfully fetched data for logger_DB.\n",
      "Fetching data for animal_DB with ID b57495033c4d4391aa5ab75de0291802\n",
      "Successfully fetched data for animal_DB.\n",
      "\n",
      "SUCCESS: 8 Data files found.\n",
      "0 Little Leonardo files: []\n",
      "\n",
      "0 Manitty files: []\n",
      "\n",
      "0 Wildlife Computers files: []\n",
      "\n",
      "0 Evolocus files: []\n",
      "\n",
      "2 UFI files: ['2024-01-16_oror-002a_UF-01_001.ubc', '2024-01-16_oror-002a_UF-01_001.ube']\n",
      "\n",
      "6 CATS files: ['2024-01-16_oror-002a_CC-96_001.bin', '2024-01-16_oror-002a_CC-96_001.csv', '2024-01-16_oror-002a_CC-96_001.txt', '2024-01-16_oror-002a_CC-96_001.ubx', '2024-01-16_oror-002a_CC-96_002.csv', '2024-01-16_oror-002a_CC-96_003.csv']\n",
      "\n",
      "Manufacturer: Little Leonardo\n",
      "Manufacturer: Manitty\n",
      "Manufacturer: Wildlife Computers\n",
      "Manufacturer: Evolocus\n",
      "Manufacturer: UFI\n",
      "\n",
      "File: 2024-01-16_oror-002a_UF-01_001.ubc - NOT a supported file type.\n",
      "Parsed download timestamp string: '01-16-2024, 11:29:42'\n",
      "Recording start time: 2024-01-16 07:15:01\n",
      "Total ECG data points: 1510713\n",
      "                timestamp   ecg\n",
      "0 2024-01-16 07:15:01.000  1316\n",
      "1 2024-01-16 07:15:01.010  1325\n",
      "2 2024-01-16 07:15:01.020  1307\n",
      "3 2024-01-16 07:15:01.030  1324\n",
      "4 2024-01-16 07:15:01.040  1316\n",
      "Data successfully saved to: c:\\Users\\fbar\\Documents\\GitHub\\Finescale-HR\\data\\2024-01-16_oror-002a_Shuka-HR\\outputs\\2024-01-16_oror-002a_UF-01_001.csv\n",
      "\n",
      "File: 2024-01-16_oror-002a_UF-01_001.ube - Successfully processed.\n",
      "Manufacturer: CATS\n",
      "\n",
      "File: 2024-01-16_oror-002a_CC-96_001.bin - NOT a supported file type.\n",
      "Attempting to read c:\\Users\\fbar\\Documents\\GitHub\\Finescale-HR\\data\\2024-01-16_oror-002a_Shuka-HR\\2024-01-16_oror-002a_CC-96_001.csv with encoding utf-8\n",
      "Error reading c:\\Users\\fbar\\Documents\\GitHub\\Finescale-HR\\data\\2024-01-16_oror-002a_Shuka-HR\\2024-01-16_oror-002a_CC-96_001.csv with encoding utf-8: 'utf-8' codec can't decode byte 0xb2 in position 20: invalid start byte\n",
      "Attempting to read c:\\Users\\fbar\\Documents\\GitHub\\Finescale-HR\\data\\2024-01-16_oror-002a_Shuka-HR\\2024-01-16_oror-002a_CC-96_001.csv with encoding ISO-8859-1\n",
      "   Date (UTC)       Time (UTC)  Date (local)     Time (local)  \\\n",
      "0  16.01.2024  17:13:56.000000    16.01.2024  09:13:56.000000   \n",
      "1  16.01.2024  17:13:56.002500    16.01.2024  09:13:56.002500   \n",
      "2  16.01.2024  17:13:56.005000    16.01.2024  09:13:56.005000   \n",
      "3  16.01.2024  17:13:56.007500    16.01.2024  09:13:56.007500   \n",
      "4  16.01.2024  17:13:56.010000    16.01.2024  09:13:56.010000   \n",
      "\n",
      "   Accelerometer X [m/s²]  Accelerometer Y [m/s²]  Accelerometer Z [m/s²]  \\\n",
      "0               -9.765949               -0.454898               -0.871489   \n",
      "1               -9.739612               -0.493206               -0.859518   \n",
      "2               -9.765949               -0.469264               -0.869095   \n",
      "3               -9.777920               -0.462081               -0.845153   \n",
      "4               -9.777920               -0.462081               -0.854730   \n",
      "\n",
      "   Gyroscope X [mrad/s]  Gyroscope Y [mrad/s]  Gyroscope Z [mrad/s]  ...  \\\n",
      "0             15.431265            -22.348728             -6.917463  ...   \n",
      "1             15.431265            -22.348728             -6.917463  ...   \n",
      "2             15.431265            -22.348728             -6.917463  ...   \n",
      "3             15.431265            -22.348728             -6.917463  ...   \n",
      "4             15.431265            -20.752390             -6.385351  ...   \n",
      "\n",
      "   BATT [V]  BATT [mA]  BATT [mAh]  Camera  Flags  LED  Camera time  GPS  \\\n",
      "0     4.125    -24.754      6826.3       0    ---    0            0    4   \n",
      "1     4.125    -24.754      6826.3       0    ---    0            0    4   \n",
      "2     4.125    -24.754      6826.3       0    ---    0            0    4   \n",
      "3     4.125    -24.754      6826.3       0    ---    0            0    4   \n",
      "4     4.125    -24.754      6826.3       0    ---    0            0    4   \n",
      "\n",
      "  CC status   CC vid. size [kBytes]  \n",
      "0       ---                       0  \n",
      "1       ---                       0  \n",
      "2       ---                       0  \n",
      "3       ---                       0  \n",
      "4       ---                       0  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "Data successfully saved to: c:\\Users\\fbar\\Documents\\GitHub\\Finescale-HR\\data\\2024-01-16_oror-002a_Shuka-HR\\outputs\\2024-01-16_oror-002a_CC-96_001.csv\n",
      "\n",
      "File: 2024-01-16_oror-002a_CC-96_001.csv - Successfully processed.\n",
      "\n",
      "File: 2024-01-16_oror-002a_CC-96_001.txt - NOT a supported file type.\n",
      "\n",
      "File: 2024-01-16_oror-002a_CC-96_001.ubx - NOT a supported file type.\n",
      "Attempting to read c:\\Users\\fbar\\Documents\\GitHub\\Finescale-HR\\data\\2024-01-16_oror-002a_Shuka-HR\\2024-01-16_oror-002a_CC-96_002.csv with encoding utf-8\n",
      "Error reading c:\\Users\\fbar\\Documents\\GitHub\\Finescale-HR\\data\\2024-01-16_oror-002a_Shuka-HR\\2024-01-16_oror-002a_CC-96_002.csv with encoding utf-8: 'utf-8' codec can't decode byte 0xb2 in position 20: invalid start byte\n",
      "Attempting to read c:\\Users\\fbar\\Documents\\GitHub\\Finescale-HR\\data\\2024-01-16_oror-002a_Shuka-HR\\2024-01-16_oror-002a_CC-96_002.csv with encoding ISO-8859-1\n",
      "   Date (UTC)       Time (UTC)  Date (local)     Time (local)  \\\n",
      "0  16.01.2024  17:55:25.550000    16.01.2024  09:55:25.550000   \n",
      "1  16.01.2024  17:55:25.552500    16.01.2024  09:55:25.552500   \n",
      "2  16.01.2024  17:55:25.555000    16.01.2024  09:55:25.555000   \n",
      "3  16.01.2024  17:55:25.557500    16.01.2024  09:55:25.557500   \n",
      "4  16.01.2024  17:55:25.560000    16.01.2024  09:55:25.560000   \n",
      "\n",
      "   Accelerometer X [m/s²]  Accelerometer Y [m/s²]  Accelerometer Z [m/s²]  \\\n",
      "0               -1.800440               -1.774103                9.263166   \n",
      "1               -1.831564               -1.721431                9.323021   \n",
      "2               -1.719037               -1.783680                9.318233   \n",
      "3               -1.647211               -1.800440                9.366117   \n",
      "4               -1.659182               -1.766921                9.466673   \n",
      "\n",
      "   Gyroscope X [mrad/s]  Gyroscope Y [mrad/s]  Gyroscope Z [mrad/s]  ...  \\\n",
      "0            196.349541            132.496032            187.835740  ...   \n",
      "1            196.349541            132.496032            187.835740  ...   \n",
      "2            196.349541            132.496032            187.835740  ...   \n",
      "3            196.349541            132.496032            187.835740  ...   \n",
      "4            212.312918            179.321938            218.698269  ...   \n",
      "\n",
      "   BATT [V]  BATT [mA]  BATT [mAh]  Camera  Flags  LED  Camera time  GPS  \\\n",
      "0    4.0062  -1135.539    6001.168      12    -T-    1         2484    4   \n",
      "1    4.0062  -1135.539    6001.168      12    -T-    1         2484    4   \n",
      "2    4.0062  -1135.539    6001.168      12    -T-    1         2484    4   \n",
      "3    4.0062  -1135.539    6001.168      12    -T-    1         2484    4   \n",
      "4    4.0062  -1135.539    6001.168      12    -T-    1         2484    4   \n",
      "\n",
      "  CC status   CC vid. size [kBytes]  \n",
      "0       R--                 3559232  \n",
      "1       R--                 3559232  \n",
      "2       R--                 3559232  \n",
      "3       R--                 3559232  \n",
      "4       R--                 3559232  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "Data successfully saved to: c:\\Users\\fbar\\Documents\\GitHub\\Finescale-HR\\data\\2024-01-16_oror-002a_Shuka-HR\\outputs\\2024-01-16_oror-002a_CC-96_002.csv\n",
      "\n",
      "File: 2024-01-16_oror-002a_CC-96_002.csv - Successfully processed.\n",
      "Attempting to read c:\\Users\\fbar\\Documents\\GitHub\\Finescale-HR\\data\\2024-01-16_oror-002a_Shuka-HR\\2024-01-16_oror-002a_CC-96_003.csv with encoding utf-8\n",
      "Error reading c:\\Users\\fbar\\Documents\\GitHub\\Finescale-HR\\data\\2024-01-16_oror-002a_Shuka-HR\\2024-01-16_oror-002a_CC-96_003.csv with encoding utf-8: 'utf-8' codec can't decode byte 0xb2 in position 20: invalid start byte\n",
      "Attempting to read c:\\Users\\fbar\\Documents\\GitHub\\Finescale-HR\\data\\2024-01-16_oror-002a_Shuka-HR\\2024-01-16_oror-002a_CC-96_003.csv with encoding ISO-8859-1\n",
      "   Date (UTC)       Time (UTC)  Date (local)     Time (local)  \\\n",
      "0  16.01.2024  18:36:38.990000    16.01.2024  10:36:38.990000   \n",
      "1  16.01.2024  18:36:38.992500    16.01.2024  10:36:38.992500   \n",
      "2  16.01.2024  18:36:38.995000    16.01.2024  10:36:38.995000   \n",
      "3  16.01.2024  18:36:38.997500    16.01.2024  10:36:38.997500   \n",
      "4  16.01.2024  18:36:39.000000    16.01.2024  10:36:39.000000   \n",
      "\n",
      "   Accelerometer X [m/s²]  Accelerometer Y [m/s²]  Accelerometer Z [m/s²]  \\\n",
      "0                0.019154                0.184354              -10.539276   \n",
      "1                0.153229               -0.373495              -10.453084   \n",
      "2                0.270545               -0.577003              -10.450690   \n",
      "3                0.392649               -0.667982              -10.388441   \n",
      "4                0.435745               -0.567426              -10.259154   \n",
      "\n",
      "   Gyroscope X [mrad/s]  Gyroscope Y [mrad/s]  Gyroscope Z [mrad/s]  ...  \\\n",
      "0              51.61492             93.119701              1.064225  ...   \n",
      "1              51.61492             93.119701              1.064225  ...   \n",
      "2              51.61492             93.119701              1.064225  ...   \n",
      "3              51.61492             93.119701              1.064225  ...   \n",
      "4               0.00000             27.669854            -23.412953  ...   \n",
      "\n",
      "   BATT [V]  BATT [mA]  BATT [mAh]  Camera  Flags  LED  Camera time  GPS  \\\n",
      "0     3.885  -1158.088    5198.809      12    -T-    1         4946    4   \n",
      "1     3.885  -1158.088    5198.809      12    -T-    1         4946    4   \n",
      "2     3.885  -1158.088    5198.809      12    -T-    1         4946    4   \n",
      "3     3.885  -1158.088    5198.809      12    -T-    1         4946    4   \n",
      "4     3.885  -1158.088    5198.809      12    -T-    1         4946    4   \n",
      "\n",
      "  CC status   CC vid. size [kBytes]  \n",
      "0       R--                 3425472  \n",
      "1       R--                 3425472  \n",
      "2       R--                 3425472  \n",
      "3       R--                 3425472  \n",
      "4       R--                 3425472  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "Data successfully saved to: c:\\Users\\fbar\\Documents\\GitHub\\Finescale-HR\\data\\2024-01-16_oror-002a_Shuka-HR\\outputs\\2024-01-16_oror-002a_CC-96_003.csv\n",
      "\n",
      "File: 2024-01-16_oror-002a_CC-96_003.csv - Successfully processed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the datareader class\n",
    "datareader = DataReader(deployment_folder)\n",
    "\n",
    "# Call the read_files method\n",
    "datareader.read_files(metadata, save_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read and concatenate CSV files in order\n",
    "def read_and_concatenate_csvs(folder_path, RecID):\n",
    "    # List and sort the CSV files\n",
    "    csv_files = sorted([file for file in os.listdir(folder_path) if file.endswith('.csv') and file.startswith(RecID)], key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "\n",
    "    # Concatenate dataframes\n",
    "    dfs = [pd.read_csv(os.path.join(folder_path, file)) for file in csv_files]\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Path and RecID\n",
    "folder_path = os.path.join(os.getcwd(), \"outputs\")\n",
    "\n",
    "# Read and concatenate data\n",
    "final_df = read_and_concatenate_csvs(folder_path, RecID)\n",
    "\n",
    "# Get datetime\n",
    "\n",
    "final_df['datetime'] = pd.to_datetime(final_df[\" Date (local)\"] + ' ' + final_df[\" Time (local)\"], format='%d.%m.%Y %H:%M:%S.%f')\n",
    "final_df['datetime'] = final_df['datetime'].dt.tz_localize(pytz.timezone('America/Los_Angeles'))\n",
    "print(final_df['datetime'][0])\n",
    "\n",
    "# Calculate time differences and cumulative sum of differences\n",
    "sec_diff = final_df['datetime'].diff().dt.total_seconds()\n",
    "final_df['cum_diff'] = np.cumsum(sec_diff)\n",
    "\n",
    "# Check for inconsistencies (time jumps)\n",
    "mean_diff = sec_diff.mean()\n",
    "time_jumps = sec_diff[sec_diff > mean_diff * 2]  # Define a threshold for time jumps\n",
    "\n",
    "# Report any inconsistencies\n",
    "if not time_jumps.empty:\n",
    "    print(f\"Time jumps detected:\\n{time_jumps}\")\n",
    "else:\n",
    "    print(\"No significant time jumps detected.\")\n",
    "    print(f\"Sampling frequency: {1 / mean_diff} Hz\")\n",
    "\n",
    "# Plot cumulative differences\n",
    "plt.plot(final_df['datetime'], final_df['cum_diff'])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Cumulative Difference (seconds)')\n",
    "plt.title('Cumulative Difference over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prep\n",
    "CO_df = final_df \n",
    "\n",
    "print(CO_df['datetime'][1]-CO_df['datetime'][0])\n",
    "CO_fs = 1/(CO_df['datetime'][1]-CO_df['datetime'][0]).total_seconds()\n",
    "CO_max_timediff = np.max(np.diff(CO_df['datetime']))\n",
    "print(f\"CATS Sampling frequency: {CO_fs} Hz with a maximum time difference of {CO_max_timediff}\")\n",
    "\n",
    "# Load the data_reader object from the pickle file\n",
    "with open('outputs/data_reader.pkl', 'rb') as file:\n",
    "    data_reader = pickle.load(file)\n",
    "\n",
    "# Get the ECG and timestamp data\n",
    "ecg_df = data_reader.data_raw['2024-06-17_oror-002-001a_UF-04_001']\n",
    "ecg_df['datetime'] = pd.to_datetime(ecg_df['timestamp'])\n",
    "ecg_df['datetime'] = ecg_df['datetime'].dt.tz_localize(pytz.timezone('America/Los_Angeles'))\n",
    "print(ecg_df['datetime'][0])\n",
    "print(ecg_df)\n",
    "\n",
    "print(ecg_df['datetime'][1]-ecg_df['datetime'][0])\n",
    "ecg_fs = 1/(ecg_df['datetime'][1]-ecg_df['datetime'][0]).total_seconds()\n",
    "ecg_max_timediff = np.max(np.diff(ecg_df['datetime']))\n",
    "print(f\"ECG Sampling frequency: {ecg_fs} Hz with a maximum time difference of {ecg_max_timediff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sampling_rate = 10\n",
    "ecg_conversion = int(ecg_fs / new_sampling_rate)\n",
    "CATS_conversion = int(CO_fs / new_sampling_rate)\n",
    "\n",
    "ecg_df10 = ecg_df.iloc[::ecg_conversion, :] # To subsample from 400Hz to 10Hz (1 out of every 40 samples)\n",
    "CO_df10 = CO_df.iloc[::CATS_conversion, :] # To subsample from 400Hz to 10Hz (1 out of every 40 samples)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(5, 1, figsize=(10, 10))\n",
    "\n",
    "axs[0].plot(CO_df10['datetime'], CO_df10['Accelerometer X [m/s²]'])\n",
    "axs[0].set_ylabel('Accelerometer X [m/s²]')\n",
    "\n",
    "axs[1].plot(CO_df10['datetime'], CO_df10['Accelerometer Y [m/s²]'])\n",
    "axs[1].set_ylabel('Accelerometer Y [m/s²]')\n",
    "\n",
    "axs[2].plot(CO_df10['datetime'], CO_df10['Accelerometer Z [m/s²]'])\n",
    "axs[2].set_ylabel('Accelerometer Z [m/s²]')\n",
    "\n",
    "axs[3].plot(CO_df10['datetime'], CO_df10['Depth (100bar) [m]'])\n",
    "axs[3].set_ylabel('Depth (100bar) [m]')\n",
    "\n",
    "axs[4].plot(ecg_df10['datetime'], ecg_df10['ecg'])\n",
    "axs[4].set_ylabel('ECG [mV]')\n",
    "\n",
    "plt.xlabel('Datetime')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "new_CATS_sampling_rate = 10\n",
    "new_ecg_sampling_rate = 50\n",
    "ecg_conversion = int(ecg_fs / new_ecg_sampling_rate)\n",
    "CATS_conversion = int(CO_fs / new_CATS_sampling_rate)\n",
    "\n",
    "ecg_df50 = ecg_df.iloc[::ecg_conversion, :]  # To subsample from 400Hz to 10Hz (1 out of every 40 samples)\n",
    "CO_df10 = CO_df.iloc[::CATS_conversion, :]  # To subsample from 400Hz to 10Hz (1 out of every 40 samples)\n",
    "\n",
    "# Create subplots\n",
    "fig = make_subplots(rows=6, cols=1, shared_xaxes=True, vertical_spacing=0.01)\n",
    "\n",
    "# Add ECG plot\n",
    "fig.add_trace(go.Scatter(x=ecg_df10['datetime'], y=ecg_df10['ecg'], mode='lines', name='ECG [mV]', line=dict(color='orange')), row=1, col=1)\n",
    "\n",
    "# Add Depth plot\n",
    "fig.add_trace(go.Scatter(x=CO_df10['datetime'], y=CO_df10['Depth (100bar) [m]'], mode='lines', name='Depth [m]', line=dict(color='purple')), row=2, col=1)\n",
    "fig.update_yaxes(autorange=\"reversed\", row=2, col=1)\n",
    "\n",
    "# Add Accelerometer plots\n",
    "fig.add_trace(go.Scatter(x=CO_df10['datetime'], y=CO_df10['Accelerometer X [m/s²]'], mode='lines', name='Accel X [m/s²]', line=dict(color='blue')), row=3, col=1)\n",
    "fig.add_trace(go.Scatter(x=CO_df10['datetime'], y=CO_df10['Accelerometer Y [m/s²]'], mode='lines', name='Accel Y [m/s²]', line=dict(color='green')), row=4, col=1)\n",
    "fig.add_trace(go.Scatter(x=CO_df10['datetime'], y=CO_df10['Accelerometer Z [m/s²]'], mode='lines', name='Accel Z [m/s²]', line=dict(color='red')), row=5, col=1)\n",
    "\n",
    "# Add Gyroscope Y plot\n",
    "fig.add_trace(go.Scatter(x=CO_df10['datetime'], y=CO_df10['Gyroscope X [mrad/s]'], mode='lines', name='Gyr X [mrad/s]', line=dict(color='pink')), row=6, col=1)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(height=800, width=1000, title_text=\"Subsampled Data Plots\", showlegend=False)\n",
    "fig.update_xaxes(title_text=\"Datetime\", row=6, col=1)\n",
    "\n",
    "# Update y-axes labels\n",
    "fig.update_yaxes(title_text=\"ECG [mV]\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Depth [m]\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Accel X [m/s²]\", row=3, col=1)\n",
    "fig.update_yaxes(title_text=\"Accel Y [m/s²]\", row=4, col=1)\n",
    "fig.update_yaxes(title_text=\"Accel Z [m/s²]\", row=5, col=1)\n",
    "fig.update_yaxes(title_text=\"Gyr X [mrad/s]\", row=6, col=1)\n",
    "\n",
    "# Show plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Metadata class\n",
    "metadata = Metadata()\n",
    "metadata.fetch_databases()\n",
    "\n",
    "# Get the logger database\n",
    "logger_db = metadata.get_metadata(\"logger_DB\")\n",
    "\n",
    "# Determine unique LoggerIDs from the logger metadata dataframe\n",
    "logger_ids = set(logger_db['LoggerID'])\n",
    "print(f\"Unique Logger IDs: {logger_ids}\")\n",
    "\n",
    "# Breakdown of loggers by type\n",
    "logger_breakdown = logger_db.groupby(['Manufacturer', 'Type']).size().reset_index(name='Count')\n",
    "print(\"Logger Breakdown by Manufacturer and Type:\")\n",
    "print(logger_breakdown)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finescale_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
